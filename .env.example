# DeepSeek Engineer v2 Configuration
# Copy this file to .env and configure your preferred AI provider

# =============================================================================
# AI PROVIDER SELECTION (Required)
# =============================================================================
# Choose your AI provider: "deepseek" for cloud or "ollama" for local
AI_PROVIDER=ollama

# =============================================================================
# DEEPSEEK CONFIGURATION (Cloud AI)
# =============================================================================
# Required if AI_PROVIDER=deepseek
# Get your API key from: https://platform.deepseek.com
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Optional: Override default DeepSeek model
# DEEPSEEK_MODEL=deepseek-reasoner

# =============================================================================
# OLLAMA CONFIGURATION (Local AI)
# =============================================================================
# Required if AI_PROVIDER=ollama
# Model to use (must be pulled first with: ollama pull model_name)
# IMPORTANT: Use models that support function calling for full features
OLLAMA_MODEL=qwen3

# Optional: Override default Ollama API URL
# OLLAMA_BASE_URL=http://localhost:11434/v1

# =============================================================================
# QUICK SETUP EXAMPLES
# =============================================================================

# Example 1: Ollama with Qwen3 (Local, Free, Function Calling) - RECOMMENDED
# AI_PROVIDER=ollama
# OLLAMA_MODEL=qwen3

# Example 2: Ollama with Llama 3.2 (Local, Free, Function Calling)
# AI_PROVIDER=ollama
# OLLAMA_MODEL=llama3.2

# Example 3: Ollama with Mistral (Local, Free, Function Calling)
# AI_PROVIDER=ollama
# OLLAMA_MODEL=mistral

# Example 4: Ollama with CodeLlama (Local, Free, Function Calling)
# AI_PROVIDER=ollama
# OLLAMA_MODEL=codellama

# Example 5: DeepSeek with Reasoning Model (Cloud, Advanced)
# AI_PROVIDER=deepseek
# DEEPSEEK_API_KEY=sk-your-actual-key-here

# =============================================================================
# OLLAMA MODELS WITH FUNCTION CALLING SUPPORT
# =============================================================================
# ✅ qwen3         - Latest Qwen model with excellent function calling (recommended)
# ✅ llama3.2      - Excellent general coding
# ✅ mistral       - Great for code analysis and generation  
# ✅ codellama     - Specialized for programming tasks
# ✅ qwen2.5       - Strong reasoning capabilities
# ✅ phi3          - Lightweight and fast
# ❌ deepseek-r1   - Does not support function calling
# ❌ gemma         - Limited function calling support

# To install a model: ollama pull model_name
# To list installed models: ollama list
# To check running models: ollama ps

# =============================================================================
# SETUP INSTRUCTIONS
# =============================================================================

# FOR OLLAMA (LOCAL):
# 1. Install Ollama: https://ollama.ai
# 2. Start service: ollama serve
# 3. Pull a model: ollama pull qwen3
# 4. Set: AI_PROVIDER=ollama and OLLAMA_MODEL=qwen3
# 5. Run: python deepseek-eng.py

# FOR DEEPSEEK (CLOUD):
# 1. Get API key: https://platform.deepseek.com
# 2. Set: AI_PROVIDER=deepseek and DEEPSEEK_API_KEY=your_key
# 3. Run: python deepseek-eng.py

# =============================================================================
# NOTES
# =============================================================================
# - Restart the application after changing AI_PROVIDER
# - Ollama models run locally and don't require internet after download
# - DeepSeek provides advanced reasoning but requires API costs
# - You can switch between providers anytime by updating this file